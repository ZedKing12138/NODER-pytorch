{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从训练好的模型进行推断，以生成想要的图像\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from Utils.Utls import *\n",
    "from Utils.Loss import *\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from Network.DynamicNet import DynamicNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_root_path = \"./Mri_data/\"\n",
    "subject_path = \"002_S_4654\"\n",
    "seq_length = 9\n",
    "divide_length = 7\n",
    "#结果保存路径（包括生成图像和形变场）\n",
    "result_save_path = \"./result-save/002_S_4654\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#时间换算，将年月日格式统一变成天数\n",
    "def cal_time(visit_time):\n",
    "    separates = visit_time.split(\"-\")\n",
    "    year = int(separates[0])\n",
    "    flag_month = separates[1].split(\"0\")\n",
    "    month = int(separates[1]) if flag_month[0] != \"0\" else int(flag_month[1])\n",
    "    flag_day = separates[2].split(\"0\")\n",
    "    day = int(separates[2]) if flag_day[0] != \"0\" else int(flag_day[1])\n",
    "\n",
    "    return year*365+month*30+day\n",
    "\n",
    "\n",
    "#加载特定subject的图像和时间List\n",
    "def load_imgs_and_time(subject):\n",
    "    time_List = os.listdir(os.path.join(data_root_path,subject))\n",
    "    time_List = sorted(time_List,key = lambda x:cal_time(x))\n",
    "    img_list = []\n",
    "    for t in time_List:\n",
    "        img_list.append(load_nii(imgPath=os.path.join(data_root_path,subject,t,\"t1.nii.gz\")))\n",
    "    \n",
    "    return img_list,time_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "(144, 176, 144)\n",
      "0.0\n",
      "1.0\n",
      "[0.0, 0.22465753424648938, 0.5424657534247217, 1.030136986301386, 2.05479452054783, 4.038356164383458, 5.076712328767144, 6.128767123287616, 7.15068493150693]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "imgs,times =load_imgs_and_time(subject_path)\n",
    "#计算时间\n",
    "times = [cal_time(t)/365.0 for t in times]\n",
    "start_time = times[0]\n",
    "times = [t-start_time for t in times]\n",
    "\n",
    "print(len(imgs))\n",
    "print(imgs[0].shape)\n",
    "print(np.min(imgs[0]))\n",
    "print(np.max(imgs[0]))\n",
    "print(times)\n",
    "\n",
    "#划分训练和测试的部分\n",
    "train_List = imgs[0:divide_length]\n",
    "test_List =imgs[divide_length:]\n",
    "train_times = times[0:divide_length]\n",
    "test_times = times[divide_length:]\n",
    "\n",
    "print(len(test_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "im_shape =train_List[0].shape\n",
    "#numpy转tensor,增加batch和channel维度，方便后续输入到模型\n",
    "#160*192*144\n",
    "train_List = [torch.from_numpy(img).to(device).float().unsqueeze(0).unsqueeze(0) for img in train_List]\n",
    "test_List = [torch.from_numpy(img).to(device).float().unsqueeze(0).unsqueeze(0) for img in test_List]\n",
    "img_List = train_List+test_List\n",
    "\n",
    "print(len(img_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络v\n",
    "Network = DynamicNet(img_sz=im_shape,\n",
    "                    smoothing_kernel='AK',\n",
    "                    smoothing_win=15,\n",
    "                    smoothing_pass=1,\n",
    "                    ds=2,\n",
    "                    bs=32\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicNet(\n",
       "  (enc_conv2): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), padding_mode=replicate)\n",
       "  (enc_conv3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), padding_mode=replicate)\n",
       "  (enc_conv4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), padding_mode=replicate)\n",
       "  (enc_conv5): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), padding_mode=replicate)\n",
       "  (enc_conv6): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), padding_mode=replicate)\n",
       "  (lin1): Linear(in_features=1728, out_features=32, bias=True)\n",
       "  (lin2): Linear(in_features=32, out_features=171072, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sk): AveragingKernel()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#从保存的参数文件中恢复模型(第300个epoch)\n",
    "savePath = \"./model-save/002_S_4654/epoch-300.pkl\"\n",
    "Network.load_state_dict(torch.load(savePath))\n",
    "Network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "scale_factor = torch.tensor(im_shape).to(device).view(1, 3, 1, 1, 1) * 1.\n",
    "ST = SpatialTransformer(im_shape).to(device)  # spatial transformer to warp image\n",
    "grid = generate_grid3D_tensor(im_shape).unsqueeze(0).to(device)  # [-1,1] 1*3*144*176*144\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr: 29.795058727007188\n",
      "psnr: 27.548580055743322\n",
      "psnr: 30.39480238770873\n",
      "psnr: 26.908640197759258\n",
      "psnr: 30.456358493130047\n",
      "psnr: 27.721646233110043\n",
      "psnr: 24.738872237485133\n",
      "psnr: 24.13506675441951\n",
      "MSE 评估结果为：\n",
      "[tensor(0.0010), tensor(0.0018), tensor(0.0009), tensor(0.0020), tensor(0.0009), tensor(0.0017), tensor(0.0034), tensor(0.0039)]\n",
      "训练部分的平均MSE为： 0.0013912758\n",
      "测试部分的平均MSE为： 0.0036087064\n",
      "整个序列上的平均MSE为： 0.0019456334\n"
     ]
    }
   ],
   "source": [
    "#利用训练好的模型来进行回归，得到结果\n",
    "all_phi = odeint(func = Network, y0 = grid, t=torch.tensor(times).to(device),method=\"rk4\",rtol=1e-3,atol=1e-5).to(device)\n",
    "all_v = all_phi[1:] - all_phi[:-1]\n",
    "all_phi = (all_phi + 1.) / 2. * scale_factor  # [-1, 1] -> voxel spacing\n",
    "grid_voxel = (grid + 1.) / 2. * scale_factor  # [-1, 1] -> voxel spacing\n",
    "\n",
    "#用MSE进行评估\n",
    "regression_MSE = []\n",
    "\n",
    "\n",
    "#对每一个时间点的预测进行loss计算\n",
    "for n in range(1,seq_length):\n",
    "    phi = all_phi[n]\n",
    "    df = phi - grid_voxel  # with grid -> without grid\n",
    "    warped_moving, df_with_grid = ST(img_List[0], df, return_phi=True)\n",
    "    loss_mse = MSE(warped_moving,img_List[n])\n",
    "\n",
    "    from skimage.metrics import peak_signal_noise_ratio\n",
    "    print(\"psnr:\",peak_signal_noise_ratio(warped_moving.detach().cpu().numpy(),img_List[n].detach().cpu().numpy()))    \n",
    "    regression_MSE.append(loss_mse.clone().detach().cpu())\n",
    "    warped_moving = warped_moving.squeeze(0).squeeze(0)\n",
    "\n",
    "    #保存形变场及图像\n",
    "    save_nii(df.permute(2,3,4,0,1).detach().cpu().numpy(), '%s/df-t%d.nii.gz' % (result_save_path,n))\n",
    "    save_nii(warped_moving.detach().cpu().numpy(), '%s/warped-t%d.nii.gz' % (result_save_path,n))\n",
    "\n",
    "print(\"MSE 评估结果为：\")\n",
    "print(regression_MSE)\n",
    "print(\"训练部分的平均MSE为：\",np.mean(regression_MSE[0:divide_length-1]))\n",
    "print(\"测试部分的平均MSE为：\",np.mean(regression_MSE[divide_length-1:]))\n",
    "print(\"整个序列上的平均MSE为：\",np.mean(regression_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
